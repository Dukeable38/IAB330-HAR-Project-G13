{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b397a500",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import fft, stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pickle\n",
    "\n",
    "# Load and preprocess data (polish raw)\n",
    "def preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    # Clean: Remove NaNs, normalize (zero-mean, unit variance)\n",
    "    df = df.dropna()\n",
    "    for col in ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']:\n",
    "        df[col] = (df[col] - df[col].mean()) / df[col].std()\n",
    "    # Add label column if not present (manual in CSV)\n",
    "    return df\n",
    "\n",
    "# Feature extraction (transform to meaningful reps)\n",
    "def extract_features(df, window_size=100, step=50):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - window_size, step):\n",
    "        window = df.iloc[i:i+window_size]\n",
    "        row_features = []\n",
    "        for col in ['accel_x', 'accel_y', 'accel_z', 'gyro_x', 'gyro_y', 'gyro_z']:\n",
    "            signal = window[col].values\n",
    "            # Time-domain: Mean, std, min, max, skewness\n",
    "            row_features.extend([np.mean(signal), np.std(signal), np.min(signal), np.max(signal), stats.skew(signal)])\n",
    "            # Frequency-domain: Dominant freq (FFT)\n",
    "            fft_vals = np.abs(fft.fft(signal))\n",
    "            dominant_freq = np.argmax(fft_vals)\n",
    "            row_features.append(dominant_freq)\n",
    "        features.append(row_features)\n",
    "        # Label: Mode of labels in window (assume 'label' column)\n",
    "        labels.append(window['label'].mode()[0])\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Example: Load, preprocess, extract\n",
    "df_pushup = preprocess_data('pushup_data.csv')\n",
    "X_pushup, y_pushup = extract_features(df_pushup)\n",
    "\n",
    "# Combine datasets (repeat for squat, plank)\n",
    "# X = np.vstack([X_pushup, X_squat, X_plank])\n",
    "# y = np.hstack([y_pushup, y_squat, y_plank])\n",
    "\n",
    "# Train/test split (Week 8: k-fold CV for robustness)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train models (KNN, RF per Report A)\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_knn))\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"RF Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "# Save models for Pi deployment (Week 6: Edge inference)\n",
    "pickle.dump(rf, open('har_model.pkl', 'wb'))  # Use RF as primary"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
